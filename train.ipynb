{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mm909/Predicting-Trump\n",
    "    \n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from shutil import copyfile\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, GRU, Embedding, TimeDistributed, BatchNormalization, Bidirectional\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "import import_ipynb\n",
    "from MLEXPS.MLEXPS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXT File Name: todes\n",
      "corpus length: 4293166\n"
     ]
    }
   ],
   "source": [
    "file_name = input('TXT File Name: ')\n",
    "text = open(file_name+'.txt', encoding=\"utf8\").read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 63\n",
      "num training examples: 1073272\n",
      "X.shape: (1073272, 80, 63)\n",
      "y.shape: (1073272, 63)\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(f'unique chars: {len(chars)}')\n",
    "\n",
    "SEQUENCE_LENGTH = 80\n",
    "step = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
    "print(f'num training examples: {len(sentences)}')\n",
    "\n",
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Model\n",
    "# model = load_model('D:/Predictive-Text/experiments/predictiveTrump/20200330-140314/weights/weights-improvement-04-0.6747.hdf5')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CudDNNLSTM not working so I changed it to LSTM -> See following forum\n",
    "# https://forums.developer.nvidia.com/t/importerror-cannot-import-name-cudnnlstm-from-tensorflow-keras-layers/82778/3\n",
    "# model.add(CuDNNLSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "\n",
    "model.add(LSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "# reduce_lr = keras.callbacks.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.7, patience=2, min_lr=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "models = [model]\n",
    "args = [{'x':X,\n",
    "         'y':y,\n",
    "         'batch_size':124,\n",
    "         'epochs':5,\n",
    "#          'epochs':50,\n",
    "         'shuffle':False,\n",
    "         'validation_split':0.05,}]\n",
    "         # 'callbacks': [reduce_lr]\n",
    "\n",
    "ml = MLEXPS()\n",
    "ml.setTopic('todes')\n",
    "ml.setCopyFileList(['train.ipynb'])\n",
    "ml.setModels(models)\n",
    "ml.setArgList(args)\n",
    "ml.saveBestOnly = False\n",
    "ml.startExprQ()\n",
    "\n",
    "model.save('./models/todes_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLEXPS v3\n",
      "Length of queue: 1\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 315)               477540    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 315)               1260      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 315)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 126)               39816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 126)               504       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 126)               504       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 63)                8001      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 63)                0         \n",
      "=================================================================\n",
      "Total params: 543,627\n",
      "Trainable params: 542,493\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/5\n",
      "8223/8223 [==============================] - 2526s 307ms/step - loss: 2.1096 - accuracy: 0.3889 - val_loss: 1.8631 - val_accuracy: 0.4598\n",
      "Epoch 2/5\n",
      "8223/8223 [==============================] - 2541s 309ms/step - loss: 1.8209 - accuracy: 0.4729 - val_loss: 1.6495 - val_accuracy: 0.5273\n",
      "Epoch 3/5\n",
      "8223/8223 [==============================] - 8026s 976ms/step - loss: 1.6757 - accuracy: 0.5161 - val_loss: 1.5501 - val_accuracy: 0.5555\n",
      "Epoch 4/5\n",
      "8223/8223 [==============================] - 33119s 4s/step - loss: 1.6058 - accuracy: 0.5377 - val_loss: 1.4771 - val_accuracy: 0.5729\n",
      "Epoch 5/5\n",
      "8223/8223 [==============================] - 2591s 315ms/step - loss: 1.5370 - accuracy: 0.5569 - val_loss: 1.4335 - val_accuracy: 0.5875\n"
     ]
    }
   ],
   "source": [
    "# Making Model\n",
    "# model = load_model('D:/Predictive-Text/experiments/predictiveTrump/20200330-140314/weights/weights-improvement-04-0.6747.hdf5')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CudDNNLSTM not working so I changed it to LSTM -> See following forum\n",
    "# https://forums.developer.nvidia.com/t/importerror-cannot-import-name-cudnnlstm-from-tensorflow-keras-layers/82778/3\n",
    "# model.add(CuDNNLSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "\n",
    "model.add(LSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars)),dropout=0.25))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "# reduce_lr = keras.callbacks.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.7, patience=2, min_lr=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "models = [model]\n",
    "args = [{'x':X,\n",
    "         'y':y,\n",
    "         'batch_size':124,\n",
    "         'epochs':5,\n",
    "#          'epochs':50,\n",
    "         'shuffle':False,\n",
    "         'validation_split':0.05,}]\n",
    "         # 'callbacks': [reduce_lr]\n",
    "\n",
    "ml = MLEXPS()\n",
    "ml.setTopic('todes')\n",
    "ml.setCopyFileList(['train.ipynb'])\n",
    "ml.setModels(models)\n",
    "ml.setArgList(args)\n",
    "ml.saveBestOnly = False\n",
    "ml.startExprQ()\n",
    "\n",
    "model.save('./models/todes_model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Felipe's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLEXPS v3\n",
      "Length of queue: 1\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 315)               477540    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 315)               1260      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 315)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 126)               39816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 126)               504       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 126)               16002     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 126)               504       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 63)                8001      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 63)                0         \n",
      "=================================================================\n",
      "Total params: 543,627\n",
      "Trainable params: 542,493\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/5\n",
      "8223/8223 [==============================] - 3011s 366ms/step - loss: 2.1889 - accuracy: 0.3650 - val_loss: 2.3147 - val_accuracy: 0.3440\n",
      "Epoch 2/5\n",
      "8223/8223 [==============================] - 2511s 305ms/step - loss: 1.8885 - accuracy: 0.4534 - val_loss: 1.6855 - val_accuracy: 0.5129\n",
      "Epoch 3/5\n",
      "8223/8223 [==============================] - 2435s 296ms/step - loss: 1.7100 - accuracy: 0.5056 - val_loss: 1.5469 - val_accuracy: 0.5569\n",
      "Epoch 4/5\n",
      "8223/8223 [==============================] - 2536s 308ms/step - loss: 1.6199 - accuracy: 0.5334 - val_loss: 1.4910 - val_accuracy: 0.5698\n",
      "Epoch 5/5\n",
      "8223/8223 [==============================] - 2299s 280ms/step - loss: 1.5757 - accuracy: 0.5465 - val_loss: 1.4518 - val_accuracy: 0.5838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(len(chars) * 5, input_shape=(SEQUENCE_LENGTH, len(chars)), dropout=0.25))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "models = [model]\n",
    "args = [{'x':X,\n",
    "         'y':y,\n",
    "         'batch_size':124,\n",
    "         'epochs':5,\n",
    "#          'epochs':50,\n",
    "         'shuffle':False,\n",
    "         'validation_split':0.05,}]\n",
    "         # 'callbacks': [reduce_lr]\n",
    "\n",
    "ml = MLEXPS()\n",
    "ml.setTopic('todes')\n",
    "ml.setCopyFileList(['train.ipynb'])\n",
    "ml.setModels(models)\n",
    "ml.setArgList(args)\n",
    "ml.saveBestOnly = False\n",
    "ml.startExprQ()\n",
    "\n",
    "\n",
    "model.save('./models/todes_felipe_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## felipe's other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "\n",
    "# model.add(Embedding(len(chars), 32, input_length=80))\n",
    "\n",
    "# model.add(Bidirectional(LSTM(16, dropout=0.25, return_sequences=True)))\n",
    "\n",
    "\n",
    "# model.add(TimeDistributed(Dense(len(chars))))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# optimizer = Adam(lr=0.001)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X, y, batch_size=128, epochs=5, verbose=1, shuffle=True, validation_split=0.2)\n",
    "# model.save('felipe_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('Ironhack': conda)",
   "language": "python",
   "name": "python37664bitironhackconda2e1d8dd202d44dc690958f22a90cf36f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
