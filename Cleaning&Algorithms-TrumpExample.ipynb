{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk  \n",
    "import numpy as np  \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump example\n",
    "\n",
    "Article\n",
    "https://towardsdatascience.com/tweet-generation-with-neural-networks-lstm-and-gpt-2-e163bfd3fbd8\n",
    "\n",
    "Repo\n",
    "https://github.com/mm909/Predicting-Trump/blob/master/predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove tweets whose lengths were less than 60 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Divide tweets into sequences of equal lengths and place them into a list called sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Vectorization** is the next step. Here, we split the tweets into x and y evenly. x is a 3D matrix that has the shape of the total number of sentences, length of steps(40), and the number of unique characters. y is a 2D matrix that has the total length of sentences and unique characters and the purpose of this vector is to retrieve the next character that’s after a sentence given by x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/predicting-trump-tweets-with-a-rnn-95e7c398b18e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('todes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get full text from df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for tweet in df.full_text:\n",
    "    text += tweet\n",
    "    \n",
    "text = text.lower()\n",
    "text = text.replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cleaning functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLinks(text):\n",
    "    return re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "\n",
    "def removeEmojis(text):\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "def removeEllipsis(text):\n",
    "    return re.sub('\\.\\.[\\.]*', \" \", text)\n",
    "\n",
    "def removeParens(text):\n",
    "    return re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "\n",
    "def removeLF(text):\n",
    "    text = re.sub('\\n',' ', text)\n",
    "    text = re.sub(' [ ]*', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = removeLinks(text)\n",
    "text = removeEllipsis(text)\n",
    "text = removeEmojis(text)\n",
    "text = removeParens(text)\n",
    "text = removeLF(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207166"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chars: 58\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print('Unique Chars:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 80\n",
    "step_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step_size):\n",
    "    sentences.append(text[i: i + sequence_length])\n",
    "    next_chars.append(text[i + sequence_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuences hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.zeros((len(sentences), sequence_length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (51772, 80, 58)\n",
      "Y.shape: (51772, 58)\n"
     ]
    }
   ],
   "source": [
    "print('X.shape:', X.shape)\n",
    "\n",
    "print('Y.shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(len(chars) * 5, input_shape=(sequence_length, len(chars))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars) * 2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "397/397 [==============================] - 92s 231ms/step - loss: 2.4489 - accuracy: 0.3322 - val_loss: 2.7401 - val_accuracy: 0.1858\n",
      "Epoch 2/4\n",
      "397/397 [==============================] - 93s 233ms/step - loss: 2.0928 - accuracy: 0.3867 - val_loss: 2.4463 - val_accuracy: 0.2997\n",
      "Epoch 3/4\n",
      "397/397 [==============================] - 94s 236ms/step - loss: 2.0065 - accuracy: 0.4101 - val_loss: 2.9461 - val_accuracy: 0.2441\n",
      "Epoch 4/4\n",
      "397/397 [==============================] - 93s 235ms/step - loss: 1.9367 - accuracy: 0.4300 - val_loss: 2.2962 - val_accuracy: 0.3291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3f258310>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.05, batch_size=124, epochs=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the Datacamp example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_text(sentence, n):\n",
    "    generated = sentence\n",
    "#     generated += sentence\n",
    "    for i in range(n):\n",
    "    # Create a 3-D zero vector to contain the encoding of sentence.\n",
    "        maxlen =40\n",
    "        x_pred = np.zeros((1, sequence_length, len(chars)))\n",
    "        \n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "        # Get probability distribution for the next character\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        #print(preds)\n",
    "    \n",
    "        # Get the character with maximum probability\n",
    "        next_index = np.argmax(preds)\n",
    "        #next_index = random.sample(list(preds),0.7)\n",
    "        next_index = random.choice(sorted(enumerate(preds),\n",
    "                       key=lambda x: x[1]\n",
    "                       )[-15:])[0]\n",
    "# write an if statement to check if most recent character generated is a space, if it is then generate randomly next character\n",
    "# from -15 to -1 (from some array without array)\n",
    "\n",
    "        next_char = indices_char[next_index]\n",
    "    \n",
    "        # Append the new character to the next input and generated text\n",
    "        sentence = sentence[1:] + next_char\n",
    "        generated += next_char\n",
    "    \n",
    "    # Print the generated text\n",
    "    print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esa gente debe parary# ad#dctnsils tcdto\n"
     ]
    }
   ],
   "source": [
    "# Input sequence and generate text\n",
    "sentence = \"esa gente debe parar\"\n",
    "generate_text(sentence, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('Ironhack': conda)",
   "language": "python",
   "name": "python37664bitironhackconda2e1d8dd202d44dc690958f22a90cf36f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
